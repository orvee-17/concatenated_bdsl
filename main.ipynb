{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trial_hands_3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4fsqVGqUix_l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607525006227,"user_tz":-360,"elapsed":59521,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"a60e872e-c806-465b-e948-c0e21b0ec71e"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","import os\n","os.chdir('/content/drive/My Drive/Pose Estimation/orvee/Pretrained openpose')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BNhY7uh7dt_S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gumW3lBPduAc","executionInfo":{"status":"ok","timestamp":1612197680030,"user_tz":-360,"elapsed":1309,"user":{"displayName":"Khondokar S. S. Prottoy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuj0fu3z3_EOnPHn2DMiXCFImPebpE2uO3zuHo=s64","userId":"08979871299345498283"}},"outputId":"f23839dd-9a25-45b4-b5a9-6f6d30e30777"},"source":["!cat /proc/cpuinfo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pf21-XUs7ku6","executionInfo":{"status":"ok","timestamp":1607525134444,"user_tz":-360,"elapsed":95826,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"c38b1149-515d-4ef4-ee44-ef15908a5f62"},"source":["!pip install tensorflow==2.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 23kB/s \n","\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (2.10.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.18.5)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.33.2)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.6.3)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 45.0MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (3.12.4)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.1.2)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.4.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.3.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.10.0)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 41.6MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.12.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.35.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.15.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (50.3.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.17.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.7.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.4.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-zPehBMvi3_p"},"source":["from __future__ import division\n","import os\n","import cv2\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from keras import Model, Sequential, utils\n","from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n","from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.models import load_model\n","\n","import pandas as pd \n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator, load_img\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import LabelBinarizer\n","import matplotlib.pyplot as plt\n","from random import shuffle\n","import os\n","from keras.models import Model, Sequential, load_model\n","from keras import layers\n","from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D, ZeroPadding2D, concatenate, Input, Permute, Concatenate, BatchNormalization\n","from keras import applications\n","#from keras.utils import plot_model, to_categorical\n","from keras.applications import VGG16, ResNet50\n","from keras.optimizers import RMSprop,Adam  \n","from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","import pickle\n","import random\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usvhouu9i4C3"},"source":["# DATA LOADER\n","data_dict = dict()\n","data_dict_test = dict()\n","validation_dict = dict()\n","test_dict = dict()\n","\n","data_dict['X'] = np.load('bangla_dataset/np_files/imglist_t.npy', allow_pickle=True) #DATASET.train_folder + '/images.npy'\n","data_dict['X2'] = np.load('bangla_dataset/np_files/poselist_t.npy', allow_pickle=True)\n","data_dict['Y'] = np.load('bangla_dataset/np_files/labellist_t.npy', allow_pickle=True)\n","\n","data_dict_test['X'] = np.load('bangla_dataset/np_files/imglist_v.npy', allow_pickle=True) #DATASET.train_folder + '/images.npy'\n","data_dict_test['X2'] = np.load('bangla_dataset/np_files/poselist_v.npy', allow_pickle=True)\n","data_dict_test['Y'] = np.load('bangla_dataset/np_files/labellist_v.npy', allow_pickle=True)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xZZTo65euCu"},"source":["### Main Model"]},{"cell_type":"code","metadata":{"id":"b9jhTP76e1lo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607107216920,"user_tz":-360,"elapsed":3465,"user":{"displayName":"Khondokar S. S. Prottoy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuj0fu3z3_EOnPHn2DMiXCFImPebpE2uO3zuHo=s64","userId":"08979871299345498283"}},"outputId":"f47ea543-0e0f-47db-f07b-3041051b9a1e"},"source":["image_network = Input(shape = [64, 64, 1], name = \"input_1\")\n","x=Convolution2D(64, (3, 3), padding = 'same', input_shape = (64, 64))(image_network)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(64, (3, 3), padding = 'same')(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.2)(x)\n","\n","x=Convolution2D(128, (3, 3), padding = 'same')(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(128, (3, 3), padding = 'same')(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.2)(x)\n","\n","x=Convolution2D(256, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(256, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(256, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.2)(x)\n","\n","x=Convolution2D(512, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(512, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(512, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.3)(x)\n","\n","x = Flatten()(x)\n","x = Dense(1024, activation = 'relu')(x)\n","x=BatchNormalization()(x)\n","x=Dropout(0.3)(x)\n","w = Dense(512, activation = 'relu')(x)\n","w=Dropout(0.3)(w)\n","pose_network = Input(shape = [21, 2], name = \"input_2\")\n","\n","x2 = Flatten()(pose_network)\n","x2 = Dense(1024, activation = 'relu')(x2)\n","x2=Dropout(0.3)(x2)\n","z = Dense(512, activation = 'relu')(x2)\n","z=Dropout(0.3)(z)\n","\n","\n","merged_network = concatenate([w, z], axis = 1)\n","merged_network = Dense(512, activation = 'elu')(merged_network)\n","merged_network = Dense(256, activation = 'elu')(merged_network)\n","merged_network=BatchNormalization()(merged_network)\n","merged_network = Dense(38, activation = 'softmax')(merged_network)\n","\n","model = Model(inputs = [image_network, pose_network], outputs = merged_network)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 64, 64, 64)   640         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 64, 64, 64)   0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 64, 64, 64)   256         activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 64, 64, 64)   36928       batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 32, 32, 64)   0           max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 128)  73856       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 128)  0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 128)  147584      batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 128)  0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         activation_3[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 16, 16, 128)  0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 16, 16, 256)  295168      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 16, 16, 256)  0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 16, 16, 256)  0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 16, 16, 256)  1024        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 8, 8, 256)    0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 8, 8, 512)    1180160     dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 8, 8, 512)    0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 8, 8, 512)    2359808     batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 8, 8, 512)    0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 8, 8, 512)    2359808     batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 8, 8, 512)    0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 8, 8, 512)    2048        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 512)    0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 4, 4, 512)    0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 8192)         0           dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 21, 2)]      0                                            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         8389632     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 42)           0           input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 1024)         4096        dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1024)         44032       flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          524800      dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 1024)         0           dropout_5[0][0]                  \n","                                                                 dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          524800      concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 256)          1024        dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 38)           9766        batch_normalization_11[0][0]     \n","==================================================================================================\n","Total params: 17,799,142\n","Trainable params: 17,791,206\n","Non-trainable params: 7,936\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zUWzHeGNlkfS"},"source":["# model = load_model(\"final_weights/64_MainModelepoch30.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYFlFfowi4q_"},"source":["model.compile(loss='categorical_crossentropy',\n","             optimizer=Adam(lr=0.00020000000949949026),\n","             metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_E2n4VLi4x3"},"source":["checkpoint = ModelCheckpoint(\n","                             'final_weights/64_MainModelepoch20_30.h5',\n","                             monitor='val_loss',\n","                             mode='min',\n","                             save_best_only=True, \n","                             verbose=1)\n","\n","earlystop = EarlyStopping(                   \n","                          monitor='val_loss',\n","                          min_delta=0,\n","                          restore_best_weights=True,\n","                          patience=20,\n","                          verbose=1)\n","\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.2, \n","                                            min_lr=0.000001)\n","\n","callbacks = [earlystop,checkpoint,learning_rate_reduction]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0fY4qq44CSW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cfbfd2ac-a39a-4eaa-e3bd-2a65bc2a04d0"},"source":["H = model.fit([data_dict['X'], data_dict['X2']],\n","\tdata_dict['Y'],\n","\tvalidation_data=([data_dict_test['X'], data_dict_test['X2']],\n","\tdata_dict_test['Y']),\n","\tepochs=30,\n","  callbacks=callbacks,\n","\tverbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","312/312 [==============================] - ETA: 0s - loss: 2.3383 - accuracy: 0.3296\n","Epoch 00001: val_loss improved from inf to 5.47874, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1512s 5s/step - loss: 2.3383 - accuracy: 0.3296 - val_loss: 5.4787 - val_accuracy: 0.1633 - lr: 0.0010\n","Epoch 2/30\n","312/312 [==============================] - ETA: 0s - loss: 1.1813 - accuracy: 0.6268\n","Epoch 00002: val_loss improved from 5.47874 to 0.97384, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1518s 5s/step - loss: 1.1813 - accuracy: 0.6268 - val_loss: 0.9738 - val_accuracy: 0.6878 - lr: 0.0010\n","Epoch 3/30\n","312/312 [==============================] - ETA: 0s - loss: 0.9100 - accuracy: 0.7124\n","Epoch 00003: val_loss did not improve from 0.97384\n","312/312 [==============================] - 1508s 5s/step - loss: 0.9100 - accuracy: 0.7124 - val_loss: 1.0742 - val_accuracy: 0.6815 - lr: 0.0010\n","Epoch 4/30\n","312/312 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.7600\n","Epoch 00004: val_loss improved from 0.97384 to 0.81560, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1507s 5s/step - loss: 0.7613 - accuracy: 0.7600 - val_loss: 0.8156 - val_accuracy: 0.7477 - lr: 0.0010\n","Epoch 5/30\n","312/312 [==============================] - ETA: 0s - loss: 0.6796 - accuracy: 0.7789\n","Epoch 00005: val_loss improved from 0.81560 to 0.69395, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1508s 5s/step - loss: 0.6796 - accuracy: 0.7789 - val_loss: 0.6940 - val_accuracy: 0.7886 - lr: 0.0010\n","Epoch 6/30\n","312/312 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.8023\n","Epoch 00006: val_loss improved from 0.69395 to 0.68329, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1507s 5s/step - loss: 0.6110 - accuracy: 0.8023 - val_loss: 0.6833 - val_accuracy: 0.7777 - lr: 0.0010\n","Epoch 7/30\n","312/312 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.8263\n","Epoch 00007: val_loss improved from 0.68329 to 0.61346, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1506s 5s/step - loss: 0.5298 - accuracy: 0.8263 - val_loss: 0.6135 - val_accuracy: 0.8167 - lr: 0.0010\n","Epoch 8/30\n","312/312 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8443\n","Epoch 00008: val_loss improved from 0.61346 to 0.51894, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1507s 5s/step - loss: 0.4914 - accuracy: 0.8443 - val_loss: 0.5189 - val_accuracy: 0.8403 - lr: 0.0010\n","Epoch 9/30\n","312/312 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.8637\n","Epoch 00009: val_loss improved from 0.51894 to 0.47289, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1514s 5s/step - loss: 0.4317 - accuracy: 0.8637 - val_loss: 0.4729 - val_accuracy: 0.8430 - lr: 0.0010\n","Epoch 10/30\n","312/312 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8428\n","Epoch 00010: val_loss improved from 0.47289 to 0.40959, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1512s 5s/step - loss: 0.4869 - accuracy: 0.8428 - val_loss: 0.4096 - val_accuracy: 0.8666 - lr: 0.0010\n","Epoch 11/30\n","312/312 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8747\n","Epoch 00011: val_loss did not improve from 0.40959\n","312/312 [==============================] - 1505s 5s/step - loss: 0.3785 - accuracy: 0.8747 - val_loss: 0.6956 - val_accuracy: 0.8004 - lr: 0.0010\n","Epoch 12/30\n","312/312 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8779\n","Epoch 00012: val_loss did not improve from 0.40959\n","312/312 [==============================] - 1505s 5s/step - loss: 0.3740 - accuracy: 0.8779 - val_loss: 0.5372 - val_accuracy: 0.8385 - lr: 0.0010\n","Epoch 13/30\n","312/312 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8812\n","Epoch 00013: val_loss improved from 0.40959 to 0.39157, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1513s 5s/step - loss: 0.3628 - accuracy: 0.8812 - val_loss: 0.3916 - val_accuracy: 0.8838 - lr: 0.0010\n","Epoch 14/30\n","312/312 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8918\n","Epoch 00014: val_loss did not improve from 0.39157\n","312/312 [==============================] - 1508s 5s/step - loss: 0.3296 - accuracy: 0.8918 - val_loss: 0.4945 - val_accuracy: 0.8702 - lr: 0.0010\n","Epoch 15/30\n","312/312 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.8358\n","Epoch 00015: val_loss improved from 0.39157 to 0.29169, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1527s 5s/step - loss: 0.5181 - accuracy: 0.8358 - val_loss: 0.2917 - val_accuracy: 0.9065 - lr: 0.0010\n","Epoch 16/30\n","312/312 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.9013\n","Epoch 00016: val_loss did not improve from 0.29169\n","312/312 [==============================] - 1531s 5s/step - loss: 0.2926 - accuracy: 0.9013 - val_loss: 0.6185 - val_accuracy: 0.8221 - lr: 0.0010\n","Epoch 17/30\n","312/312 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.9163\n","Epoch 00017: val_loss did not improve from 0.29169\n","312/312 [==============================] - 1518s 5s/step - loss: 0.2542 - accuracy: 0.9163 - val_loss: 0.3468 - val_accuracy: 0.8984 - lr: 0.0010\n","Epoch 18/30\n","312/312 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.9148\n","Epoch 00018: val_loss did not improve from 0.29169\n","\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","312/312 [==============================] - 1524s 5s/step - loss: 0.2470 - accuracy: 0.9148 - val_loss: 0.3109 - val_accuracy: 0.9120 - lr: 0.0010\n","Epoch 19/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9564\n","Epoch 00019: val_loss improved from 0.29169 to 0.19217, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1520s 5s/step - loss: 0.1323 - accuracy: 0.9564 - val_loss: 0.1922 - val_accuracy: 0.9383 - lr: 2.0000e-04\n","Epoch 20/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9680\n","Epoch 00020: val_loss improved from 0.19217 to 0.18363, saving model to final_weights/64_MainModelepoch30.h5\n","312/312 [==============================] - 1516s 5s/step - loss: 0.1026 - accuracy: 0.9680 - val_loss: 0.1836 - val_accuracy: 0.9465 - lr: 2.0000e-04\n","Epoch 21/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9753\n","Epoch 00021: val_loss did not improve from 0.18363\n","312/312 [==============================] - 1514s 5s/step - loss: 0.0819 - accuracy: 0.9753 - val_loss: 0.2189 - val_accuracy: 0.9374 - lr: 2.0000e-04\n","Epoch 22/30\n","142/312 [============>.................] - ETA: 13:20 - loss: 0.0835 - accuracy: 0.9769"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0OcuPSImqwQ","executionInfo":{"status":"ok","timestamp":1607250665937,"user_tz":-360,"elapsed":15974956,"user":{"displayName":"Khondokar S. S. Prottoy ,160021165","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiyezSatv38KufcX87prkjnKWOuzRY4QvMgRNm=s64","userId":"07098048821585006482"}},"outputId":"8b39fa96-506f-468a-a05d-a34fd5b26112"},"source":["H = model.fit([data_dict['X'], data_dict['X2']],\n","\tdata_dict['Y'],\n","\tvalidation_data=([data_dict_test['X'], data_dict_test['X2']],\n","\tdata_dict_test['Y']),\n","\tepochs=10,\n","  callbacks=callbacks,\n","\tverbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9696\n","Epoch 00001: val_loss improved from inf to 0.20335, saving model to final_weights/64_MainModelepoch20_30.h5\n","312/312 [==============================] - 1660s 5s/step - loss: 0.0956 - accuracy: 0.9696 - val_loss: 0.2034 - val_accuracy: 0.9392 - lr: 2.0000e-04\n","Epoch 2/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9755\n","Epoch 00002: val_loss improved from 0.20335 to 0.19003, saving model to final_weights/64_MainModelepoch20_30.h5\n","312/312 [==============================] - 1663s 5s/step - loss: 0.0757 - accuracy: 0.9755 - val_loss: 0.1900 - val_accuracy: 0.9474 - lr: 2.0000e-04\n","Epoch 3/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9795\n","Epoch 00003: val_loss did not improve from 0.19003\n","312/312 [==============================] - 1666s 5s/step - loss: 0.0668 - accuracy: 0.9795 - val_loss: 0.2043 - val_accuracy: 0.9428 - lr: 2.0000e-04\n","Epoch 4/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9811\n","Epoch 00004: val_loss did not improve from 0.19003\n","312/312 [==============================] - 1670s 5s/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.2197 - val_accuracy: 0.9410 - lr: 2.0000e-04\n","Epoch 5/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9825\n","Epoch 00005: val_loss did not improve from 0.19003\n","\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","312/312 [==============================] - 1661s 5s/step - loss: 0.0551 - accuracy: 0.9825 - val_loss: 0.2456 - val_accuracy: 0.9392 - lr: 2.0000e-04\n","Epoch 6/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9858\n","Epoch 00006: val_loss did not improve from 0.19003\n","312/312 [==============================] - 1669s 5s/step - loss: 0.0441 - accuracy: 0.9858 - val_loss: 0.2134 - val_accuracy: 0.9446 - lr: 4.0000e-05\n","Epoch 7/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9915\n","Epoch 00007: val_loss did not improve from 0.19003\n","312/312 [==============================] - 1681s 5s/step - loss: 0.0354 - accuracy: 0.9915 - val_loss: 0.2084 - val_accuracy: 0.9483 - lr: 4.0000e-05\n","Epoch 8/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9894\n","Epoch 00008: val_loss did not improve from 0.19003\n","\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","312/312 [==============================] - 1682s 5s/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.2118 - val_accuracy: 0.9474 - lr: 4.0000e-05\n","Epoch 9/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9925\n","Epoch 00009: val_loss did not improve from 0.19003\n","312/312 [==============================] - 1680s 5s/step - loss: 0.0297 - accuracy: 0.9925 - val_loss: 0.2066 - val_accuracy: 0.9474 - lr: 8.0000e-06\n","Epoch 10/10\n","312/312 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9919\n","Epoch 00010: val_loss did not improve from 0.19003\n","312/312 [==============================] - 1682s 5s/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 0.2072 - val_accuracy: 0.9492 - lr: 8.0000e-06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aozovHse4CXf"},"source":["model = model.save(\"final_weights/64_MainModelepoch30th.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6NU7AM5FTqP","executionInfo":{"status":"ok","timestamp":1607251791204,"user_tz":-360,"elapsed":62471,"user":{"displayName":"Khondokar S. S. Prottoy ,160021165","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiyezSatv38KufcX87prkjnKWOuzRY4QvMgRNm=s64","userId":"07098048821585006482"}},"outputId":"71dcb349-eb6e-4104-da83-c71ec77f45b1"},"source":["score = model.evaluate([data_dict_evaluate['X'], data_dict_evaluate['X2']],\n","\tdata_dict_evaluate['Y'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 59s 1s/step - loss: 0.3589 - accuracy: 0.9151\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X__vrVihi43_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0949e76-1647-4314-f85f-066c7be66ac8"},"source":["H = model.fit([data_dict['X'], data_dict['X2']],\n","\tdata_dict['Y'],\n","\tvalidation_data=([data_dict_test['X'], data_dict_test['X2']],\n","\tdata_dict_test['Y']),\n","\tepochs=30,\n","  callbacks=callbacks,\n","\tverbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","312/312 [==============================] - ETA: 0s - loss: 2.1492 - accuracy: 0.3675\n","Epoch 00001: val_loss improved from inf to 2.89629, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1681s 5s/step - loss: 2.1492 - accuracy: 0.3675 - val_loss: 2.8963 - val_accuracy: 0.4047 - lr: 0.0010\n","Epoch 2/30\n","312/312 [==============================] - ETA: 0s - loss: 1.1629 - accuracy: 0.6305\n","Epoch 00002: val_loss improved from 2.89629 to 1.21503, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1683s 5s/step - loss: 1.1629 - accuracy: 0.6305 - val_loss: 1.2150 - val_accuracy: 0.6316 - lr: 0.0010\n","Epoch 3/30\n","312/312 [==============================] - ETA: 0s - loss: 0.9305 - accuracy: 0.7036\n","Epoch 00003: val_loss improved from 1.21503 to 1.06417, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1680s 5s/step - loss: 0.9305 - accuracy: 0.7036 - val_loss: 1.0642 - val_accuracy: 0.6388 - lr: 0.0010\n","Epoch 4/30\n","312/312 [==============================] - ETA: 0s - loss: 0.8228 - accuracy: 0.7324\n","Epoch 00004: val_loss did not improve from 1.06417\n","312/312 [==============================] - 1679s 5s/step - loss: 0.8228 - accuracy: 0.7324 - val_loss: 1.1700 - val_accuracy: 0.6733 - lr: 0.0010\n","Epoch 5/30\n","312/312 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.7828\n","Epoch 00005: val_loss improved from 1.06417 to 0.82033, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1679s 5s/step - loss: 0.6772 - accuracy: 0.7828 - val_loss: 0.8203 - val_accuracy: 0.7396 - lr: 0.0010\n","Epoch 6/30\n","312/312 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.8026\n","Epoch 00006: val_loss improved from 0.82033 to 0.69918, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1686s 5s/step - loss: 0.6101 - accuracy: 0.8026 - val_loss: 0.6992 - val_accuracy: 0.7795 - lr: 0.0010\n","Epoch 7/30\n","312/312 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.8021\n","Epoch 00007: val_loss improved from 0.69918 to 0.37049, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1677s 5s/step - loss: 0.5978 - accuracy: 0.8021 - val_loss: 0.3705 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 8/30\n","312/312 [==============================] - ETA: 0s - loss: 0.5305 - accuracy: 0.8294\n","Epoch 00008: val_loss did not improve from 0.37049\n","312/312 [==============================] - 1679s 5s/step - loss: 0.5305 - accuracy: 0.8294 - val_loss: 0.4205 - val_accuracy: 0.8630 - lr: 0.0010\n","Epoch 9/30\n","312/312 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.8393\n","Epoch 00009: val_loss did not improve from 0.37049\n","312/312 [==============================] - 1680s 5s/step - loss: 0.4814 - accuracy: 0.8393 - val_loss: 1.0930 - val_accuracy: 0.6543 - lr: 0.0010\n","Epoch 10/30\n","312/312 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8531\n","Epoch 00010: val_loss did not improve from 0.37049\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","312/312 [==============================] - 1682s 5s/step - loss: 0.4525 - accuracy: 0.8531 - val_loss: 0.4577 - val_accuracy: 0.8721 - lr: 0.0010\n","Epoch 11/30\n","312/312 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9171\n","Epoch 00011: val_loss improved from 0.37049 to 0.19177, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1683s 5s/step - loss: 0.2600 - accuracy: 0.9171 - val_loss: 0.1918 - val_accuracy: 0.9319 - lr: 2.0000e-04\n","Epoch 12/30\n","312/312 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9326\n","Epoch 00012: val_loss improved from 0.19177 to 0.18368, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1678s 5s/step - loss: 0.2035 - accuracy: 0.9326 - val_loss: 0.1837 - val_accuracy: 0.9410 - lr: 2.0000e-04\n","Epoch 13/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9376\n","Epoch 00013: val_loss did not improve from 0.18368\n","312/312 [==============================] - 1687s 5s/step - loss: 0.1885 - accuracy: 0.9376 - val_loss: 0.1962 - val_accuracy: 0.9428 - lr: 2.0000e-04\n","Epoch 14/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9478\n","Epoch 00014: val_loss did not improve from 0.18368\n","312/312 [==============================] - 1701s 5s/step - loss: 0.1627 - accuracy: 0.9478 - val_loss: 0.1895 - val_accuracy: 0.9328 - lr: 2.0000e-04\n","Epoch 15/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9529\n","Epoch 00015: val_loss did not improve from 0.18368\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001.\n","312/312 [==============================] - 1674s 5s/step - loss: 0.1539 - accuracy: 0.9529 - val_loss: 0.1932 - val_accuracy: 0.9437 - lr: 2.0000e-04\n","Epoch 16/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9643\n","Epoch 00016: val_loss did not improve from 0.18368\n","312/312 [==============================] - 1679s 5s/step - loss: 0.1179 - accuracy: 0.9643 - val_loss: 0.1838 - val_accuracy: 0.9483 - lr: 1.0000e-04\n","Epoch 17/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9657\n","Epoch 00017: val_loss improved from 0.18368 to 0.18296, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1671s 5s/step - loss: 0.1129 - accuracy: 0.9657 - val_loss: 0.1830 - val_accuracy: 0.9474 - lr: 1.0000e-04\n","Epoch 18/30\n","312/312 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9672\n","Epoch 00018: val_loss improved from 0.18296 to 0.18211, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch30.h5\n","312/312 [==============================] - 1673s 5s/step - loss: 0.1042 - accuracy: 0.9672 - val_loss: 0.1821 - val_accuracy: 0.9456 - lr: 1.0000e-04\n","Epoch 19/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9704\n","Epoch 00019: val_loss did not improve from 0.18211\n","312/312 [==============================] - 1675s 5s/step - loss: 0.0978 - accuracy: 0.9704 - val_loss: 0.1916 - val_accuracy: 0.9474 - lr: 1.0000e-04\n","Epoch 20/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9715\n","Epoch 00020: val_loss did not improve from 0.18211\n","312/312 [==============================] - 1687s 5s/step - loss: 0.0879 - accuracy: 0.9715 - val_loss: 0.1981 - val_accuracy: 0.9419 - lr: 1.0000e-04\n","Epoch 21/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9725\n","Epoch 00021: val_loss did not improve from 0.18211\n","312/312 [==============================] - 1690s 5s/step - loss: 0.0883 - accuracy: 0.9725 - val_loss: 0.1982 - val_accuracy: 0.9437 - lr: 1.0000e-04\n","Epoch 22/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9768\n","Epoch 00022: val_loss did not improve from 0.18211\n","312/312 [==============================] - 1682s 5s/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.1890 - val_accuracy: 0.9410 - lr: 1.0000e-04\n","Epoch 23/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9779\n","Epoch 00023: val_loss did not improve from 0.18211\n","312/312 [==============================] - 1674s 5s/step - loss: 0.0726 - accuracy: 0.9779 - val_loss: 0.2096 - val_accuracy: 0.9437 - lr: 1.0000e-04\n","Epoch 24/30\n","312/312 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9794\n","Epoch 00024: val_loss did not improve from 0.18211\n","312/312 [==============================] - 1671s 5s/step - loss: 0.0659 - accuracy: 0.9794 - val_loss: 0.1934 - val_accuracy: 0.9465 - lr: 1.0000e-04\n","Epoch 25/30\n","238/312 [=====================>........] - ETA: 6:29 - loss: 0.0679 - accuracy: 0.9795"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAroszHWIV-4","executionInfo":{"status":"ok","timestamp":1606826668234,"user_tz":-360,"elapsed":3255371,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"b3d92014-dbc1-4444-db3a-f631c703bd59"},"source":["H = model.fit([data_dict['X'], data_dict['X2']],\n","\tdata_dict['Y'],\n","\tvalidation_data=([data_dict_test['X'], data_dict_test['X2']],\n","\tdata_dict_test['Y']),\n","\tepochs=12,\n","  callbacks=callbacks,\n","\tverbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9719\n","Epoch 00001: val_loss improved from inf to 0.18376, saving model to trained_weights/VGG + 512 DENSE ADDITION RELU_epoch18-30.h5\n","312/312 [==============================] - 1659s 5s/step - loss: 0.0961 - accuracy: 0.9719 - val_loss: 0.1838 - val_accuracy: 0.9428 - lr: 1.0000e-04\n","Epoch 2/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9740\n","Epoch 00002: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1664s 5s/step - loss: 0.0858 - accuracy: 0.9740 - val_loss: 0.1968 - val_accuracy: 0.9474 - lr: 1.0000e-04\n","Epoch 3/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9755\n","Epoch 00003: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1666s 5s/step - loss: 0.0828 - accuracy: 0.9755 - val_loss: 0.2002 - val_accuracy: 0.9410 - lr: 1.0000e-04\n","Epoch 4/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9765\n","Epoch 00004: val_loss did not improve from 0.18376\n","\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n","312/312 [==============================] - 1662s 5s/step - loss: 0.0770 - accuracy: 0.9765 - val_loss: 0.2104 - val_accuracy: 0.9419 - lr: 1.0000e-04\n","Epoch 5/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9815\n","Epoch 00005: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1658s 5s/step - loss: 0.0616 - accuracy: 0.9815 - val_loss: 0.1966 - val_accuracy: 0.9528 - lr: 2.0000e-05\n","Epoch 6/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9856\n","Epoch 00006: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1662s 5s/step - loss: 0.0553 - accuracy: 0.9856 - val_loss: 0.1910 - val_accuracy: 0.9519 - lr: 2.0000e-05\n","Epoch 7/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9832\n","Epoch 00007: val_loss did not improve from 0.18376\n","\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-05.\n","312/312 [==============================] - 1684s 5s/step - loss: 0.0568 - accuracy: 0.9832 - val_loss: 0.1916 - val_accuracy: 0.9501 - lr: 2.0000e-05\n","Epoch 8/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9831\n","Epoch 00008: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1679s 5s/step - loss: 0.0574 - accuracy: 0.9831 - val_loss: 0.1903 - val_accuracy: 0.9519 - lr: 1.0000e-05\n","Epoch 9/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9850\n","Epoch 00009: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1711s 5s/step - loss: 0.0522 - accuracy: 0.9850 - val_loss: 0.1909 - val_accuracy: 0.9510 - lr: 1.0000e-05\n","Epoch 10/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9867\n","Epoch 00010: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1679s 5s/step - loss: 0.0511 - accuracy: 0.9867 - val_loss: 0.1900 - val_accuracy: 0.9501 - lr: 1.0000e-05\n","Epoch 11/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9858\n","Epoch 00011: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1687s 5s/step - loss: 0.0505 - accuracy: 0.9858 - val_loss: 0.1900 - val_accuracy: 0.9519 - lr: 1.0000e-05\n","Epoch 12/12\n","312/312 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9867\n","Epoch 00012: val_loss did not improve from 0.18376\n","312/312 [==============================] - 1683s 5s/step - loss: 0.0482 - accuracy: 0.9867 - val_loss: 0.1902 - val_accuracy: 0.9528 - lr: 1.0000e-05\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cYidnl4gFTfj"},"source":["model = load_model(\"final_weights/64_MainModelepoch30th.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cc_R6uKIFTlu"},"source":["data_dict_evaluate = dict()\n","data_dict_evaluate['X'] = np.load('imglist_test.npy', allow_pickle=True)\n","data_dict_evaluate['X2'] = np.load('poselist_test.npy', allow_pickle=True)\n","data_dict_evaluate['Y'] = np.load('labellist_test.npy', allow_pickle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-DRZnN6XTct","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607525406671,"user_tz":-360,"elapsed":62367,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"f2ab8e2d-117b-4e8a-816a-3e00114e2ef7"},"source":["score = model.evaluate([data_dict_evaluate['X'], data_dict_evaluate['X2']],\n","\tdata_dict_evaluate['Y'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 60s 1s/step - loss: 0.3589 - accuracy: 0.9151\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-uN94eXt-iOS"},"source":[""],"execution_count":null,"outputs":[]}]}