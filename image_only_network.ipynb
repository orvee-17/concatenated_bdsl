{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vgg16_like.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYcBWv8-FFIK","executionInfo":{"status":"ok","timestamp":1609931766543,"user_tz":-360,"elapsed":82097,"user":{"displayName":"Khondokar S. S. Prottoy ,160021165","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiyezSatv38KufcX87prkjnKWOuzRY4QvMgRNm=s64","userId":"07098048821585006482"}},"outputId":"b0007e5e-9336-4c59-8864-799a6230cdbb"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","import os\n","os.chdir('/content/drive/My Drive/Pose Estimation/orvee/Pretrained openpose')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4ogm9_w4oX-","executionInfo":{"status":"ok","timestamp":1607066193237,"user_tz":-360,"elapsed":92742,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"7f1412e0-d461-4512-ad45-18bdd985bcaa"},"source":["!pip install tensorflow==2.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 29kB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.4.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.18.5)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.1.2)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.1.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (2.10.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.3.3)\n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/tensorboard/\u001b[0m\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 45.8MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.35.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.6.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.33.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2) (3.3.0)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 37.4MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2) (50.3.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.7.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.17.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.4.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BTtfxwRYFFjL"},"source":["from __future__ import division\n","import os\n","import cv2\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from keras import Model, Sequential, utils\n","from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n","from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.models import load_model\n","\n","import pandas as pd \n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator, load_img\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import LabelBinarizer\n","import matplotlib.pyplot as plt\n","from random import shuffle\n","import os\n","from keras.models import Model, Sequential, load_model\n","from keras import layers\n","from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D, ZeroPadding2D, concatenate, Input, Permute, Concatenate, BatchNormalization\n","from keras import applications\n","#from keras.utils import plot_model, to_categorical\n","from keras.applications import VGG16, ResNet50\n","from keras.optimizers import RMSprop,Adam  \n","from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","import pickle\n","import random\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_TR2QCdFFmC"},"source":["# DATA LOADER\n","data_dict = dict()\n","data_dict_test = dict()\n","validation_dict = dict()\n","test_dict = dict()\n","\n","data_dict['X'] = np.load('bangla_dataset/np_files/imglist_t.npy', allow_pickle=True) #DATASET.train_folder + '/images.npy'\n","data_dict['X2'] = np.load('bangla_dataset/np_files/poselist_t.npy', allow_pickle=True)\n","data_dict['Y'] = np.load('bangla_dataset/new/labellist_t.npy', allow_pickle=True)\n","\n","data_dict_test['X'] = np.load('bangla_dataset/new/imglist_v.npy', allow_pickle=True) #DATASET.train_folder + '/images.npy'\n","data_dict_test['X2'] = np.load('bangla_dataset/new/poselist_v.npy', allow_pickle=True)\n","data_dict_test['Y'] = np.load('bangla_dataset/new/labellist_v.npy', allow_pickle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jQ7DQgZuEWXS"},"source":["#FINAL64_ONLY_CNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OI8BC2v1EHNX","executionInfo":{"status":"ok","timestamp":1607006933784,"user_tz":-360,"elapsed":1772,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"24a74f8d-0a9f-4ea0-8efb-0903a57d34d9"},"source":["image_network = Input(shape = [64, 64, 1], name = \"input_1\")\n","x=Convolution2D(64, (3, 3), padding = 'same', input_shape = (64, 64))(image_network)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(64, (3, 3), padding = 'same')(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.2)(x)\n","\n","x=Convolution2D(128, (3, 3), padding = 'same')(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(128, (3, 3), padding = 'same')(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.2)(x)\n","\n","x=Convolution2D(256, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(256, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(256, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.2)(x)\n","\n","x=Convolution2D(512, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(512, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=Convolution2D(512, (3, 3), padding = 'same', input_shape = (64, 64))(x)\n","x=Activation('relu')(x)\n","x=BatchNormalization()(x)\n","x=MaxPooling2D(pool_size=(2, 2))(x)\n","x=Dropout(0.3)(x)\n","\n","x = Flatten()(x)\n","x = Dense(1024, activation = 'relu')(x)\n","x=BatchNormalization()(x)\n","x=Dropout(0.3)(x)\n","w = Dense(512, activation = 'relu')(x)\n","w=Dropout(0.3)(w)\n","# pose_network = Input(shape = [21, 2], name = \"input_2\")\n","\n","# x2 = Flatten()(pose_network)\n","# x2 = Dense(1024, activation = 'relu')(x2)\n","# x2=Dropout(0.3)(x2)\n","# z = Dense(512, activation = 'relu')(x2)\n","# z=Dropout(0.3)(z)\n","\n","\n","# merged_network = concatenate([w, z], axis = 1)\n","# merged_network = Dense(512, activation = 'elu')(merged_network)\n","# merged_network = Dense(256, activation = 'elu')(merged_network)\n","# merged_network=BatchNormalization()(merged_network)\n","merged_network = Dense(38, activation = 'softmax')(w)\n","\n","model = Model(inputs = image_network, outputs = merged_network)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 64, 64, 64)        640       \n","_________________________________________________________________\n","activation (Activation)      (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 64, 64, 64)        256       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 64, 64, 64)        36928     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 32, 32, 128)       147584    \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 16, 16, 256)       295168    \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 16, 16, 256)       1024      \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 16, 16, 256)       590080    \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 16, 16, 256)       1024      \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 16, 16, 256)       590080    \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 16, 16, 256)       1024      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 8, 8, 512)         1180160   \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 8, 8, 512)         2048      \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 8, 8, 512)         2359808   \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 8, 8, 512)         2048      \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 8, 8, 512)         2359808   \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 8, 8, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 8192)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              8389632   \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 1024)              4096      \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 38)                19494     \n","=================================================================\n","Total params: 16,582,886\n","Trainable params: 16,575,462\n","Non-trainable params: 7,424\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BzHWHtNQD9kP"},"source":["model = load_model(\"final_weights/final64_only_cnn_epoch25th.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2VK-djtFFr5"},"source":["model.compile(loss='categorical_crossentropy',\n","             optimizer=Adam(lr=.000001),\n","             metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNR11vFiFGBi"},"source":["checkpoint = ModelCheckpoint(\n","                             'final_weights/final64_only_cnn_epoch30.h5',\n","                             monitor='val_loss',\n","                             mode='min',\n","                             save_best_only=True, \n","                             verbose=1)\n","\n","earlystop = EarlyStopping(                   \n","                          monitor='val_loss',\n","                          min_delta=0,\n","                          restore_best_weights=True,\n","                          patience=20,\n","                          verbose=1)\n","\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.2, \n","                                            min_lr=0.000001)\n","\n","callbacks = [earlystop,checkpoint,learning_rate_reduction]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNrSo-8kFpgM","executionInfo":{"status":"ok","timestamp":1607048455211,"user_tz":-360,"elapsed":41116895,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"a19f827c-8b9c-47a1-fd56-a103577ba651"},"source":["H = model.fit(data_dict['X'],\n","\tdata_dict['Y'],\n","\tvalidation_data=(data_dict_test['X'],\n","\tdata_dict_test['Y']),\n","\tepochs=25,\n","  callbacks=callbacks,\n","\tverbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","312/312 [==============================] - ETA: 0s - loss: 3.3205 - accuracy: 0.2019\n","Epoch 00001: val_loss improved from inf to 3.74463, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1632s 5s/step - loss: 3.3205 - accuracy: 0.2019 - val_loss: 3.7446 - val_accuracy: 0.2305 - lr: 0.0010\n","Epoch 2/25\n","312/312 [==============================] - ETA: 0s - loss: 1.7825 - accuracy: 0.4860\n","Epoch 00002: val_loss improved from 3.74463 to 3.25563, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1652s 5s/step - loss: 1.7825 - accuracy: 0.4860 - val_loss: 3.2556 - val_accuracy: 0.1343 - lr: 0.0010\n","Epoch 3/25\n","312/312 [==============================] - ETA: 0s - loss: 1.3695 - accuracy: 0.5840\n","Epoch 00003: val_loss improved from 3.25563 to 1.24411, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1669s 5s/step - loss: 1.3695 - accuracy: 0.5840 - val_loss: 1.2441 - val_accuracy: 0.6479 - lr: 0.0010\n","Epoch 4/25\n","312/312 [==============================] - ETA: 0s - loss: 0.9860 - accuracy: 0.6980\n","Epoch 00004: val_loss did not improve from 1.24411\n","312/312 [==============================] - 1683s 5s/step - loss: 0.9860 - accuracy: 0.6980 - val_loss: 1.3158 - val_accuracy: 0.6225 - lr: 0.0010\n","Epoch 5/25\n","312/312 [==============================] - ETA: 0s - loss: 0.8589 - accuracy: 0.7394\n","Epoch 00005: val_loss improved from 1.24411 to 1.22562, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1704s 5s/step - loss: 0.8589 - accuracy: 0.7394 - val_loss: 1.2256 - val_accuracy: 0.6497 - lr: 0.0010\n","Epoch 6/25\n","312/312 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.7798\n","Epoch 00006: val_loss improved from 1.22562 to 0.91864, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1642s 5s/step - loss: 0.7276 - accuracy: 0.7798 - val_loss: 0.9186 - val_accuracy: 0.7169 - lr: 0.0010\n","Epoch 7/25\n","312/312 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.8024\n","Epoch 00007: val_loss improved from 0.91864 to 0.55649, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1644s 5s/step - loss: 0.6540 - accuracy: 0.8024 - val_loss: 0.5565 - val_accuracy: 0.8240 - lr: 0.0010\n","Epoch 8/25\n","312/312 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.8120\n","Epoch 00008: val_loss did not improve from 0.55649\n","312/312 [==============================] - 1626s 5s/step - loss: 0.6118 - accuracy: 0.8120 - val_loss: 0.5572 - val_accuracy: 0.8221 - lr: 0.0010\n","Epoch 9/25\n","312/312 [==============================] - ETA: 0s - loss: 0.5402 - accuracy: 0.8325\n","Epoch 00009: val_loss did not improve from 0.55649\n","312/312 [==============================] - 1627s 5s/step - loss: 0.5402 - accuracy: 0.8325 - val_loss: 0.7723 - val_accuracy: 0.7831 - lr: 0.0010\n","Epoch 10/25\n","312/312 [==============================] - ETA: 0s - loss: 0.5786 - accuracy: 0.8248\n","Epoch 00010: val_loss did not improve from 0.55649\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","312/312 [==============================] - 1628s 5s/step - loss: 0.5786 - accuracy: 0.8248 - val_loss: 0.7565 - val_accuracy: 0.8094 - lr: 0.0010\n","Epoch 11/25\n","312/312 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8964\n","Epoch 00011: val_loss improved from 0.55649 to 0.26794, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1641s 5s/step - loss: 0.3344 - accuracy: 0.8964 - val_loss: 0.2679 - val_accuracy: 0.9183 - lr: 2.0000e-04\n","Epoch 12/25\n","312/312 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9112\n","Epoch 00012: val_loss did not improve from 0.26794\n","312/312 [==============================] - 1637s 5s/step - loss: 0.2700 - accuracy: 0.9112 - val_loss: 0.2719 - val_accuracy: 0.9111 - lr: 2.0000e-04\n","Epoch 13/25\n","312/312 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9298\n","Epoch 00013: val_loss did not improve from 0.26794\n","312/312 [==============================] - 1636s 5s/step - loss: 0.2238 - accuracy: 0.9298 - val_loss: 0.2770 - val_accuracy: 0.9183 - lr: 2.0000e-04\n","Epoch 14/25\n","312/312 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.9407\n","Epoch 00014: val_loss improved from 0.26794 to 0.21811, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1641s 5s/step - loss: 0.1901 - accuracy: 0.9407 - val_loss: 0.2181 - val_accuracy: 0.9374 - lr: 2.0000e-04\n","Epoch 15/25\n","312/312 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9436\n","Epoch 00015: val_loss did not improve from 0.21811\n","312/312 [==============================] - 1647s 5s/step - loss: 0.1676 - accuracy: 0.9436 - val_loss: 0.2768 - val_accuracy: 0.9256 - lr: 2.0000e-04\n","Epoch 16/25\n","312/312 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9484\n","Epoch 00016: val_loss did not improve from 0.21811\n","312/312 [==============================] - 1653s 5s/step - loss: 0.1605 - accuracy: 0.9484 - val_loss: 0.3043 - val_accuracy: 0.9183 - lr: 2.0000e-04\n","Epoch 17/25\n","312/312 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9519\n","Epoch 00017: val_loss did not improve from 0.21811\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","312/312 [==============================] - 1649s 5s/step - loss: 0.1452 - accuracy: 0.9519 - val_loss: 0.2627 - val_accuracy: 0.9229 - lr: 2.0000e-04\n","Epoch 18/25\n","312/312 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9665\n","Epoch 00018: val_loss improved from 0.21811 to 0.21285, saving model to final_weights/final64_only_cnn_epoch20.h5\n","312/312 [==============================] - 1656s 5s/step - loss: 0.1034 - accuracy: 0.9665 - val_loss: 0.2128 - val_accuracy: 0.9338 - lr: 4.0000e-05\n","Epoch 19/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9690\n","Epoch 00019: val_loss did not improve from 0.21285\n","312/312 [==============================] - 1625s 5s/step - loss: 0.0948 - accuracy: 0.9690 - val_loss: 0.2257 - val_accuracy: 0.9356 - lr: 4.0000e-05\n","Epoch 20/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9743\n","Epoch 00020: val_loss did not improve from 0.21285\n","312/312 [==============================] - 1620s 5s/step - loss: 0.0798 - accuracy: 0.9743 - val_loss: 0.2136 - val_accuracy: 0.9383 - lr: 4.0000e-05\n","Epoch 21/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9730\n","Epoch 00021: val_loss did not improve from 0.21285\n","\n","Epoch 00021: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","312/312 [==============================] - 1609s 5s/step - loss: 0.0781 - accuracy: 0.9730 - val_loss: 0.2235 - val_accuracy: 0.9374 - lr: 4.0000e-05\n","Epoch 22/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9799\n","Epoch 00022: val_loss did not improve from 0.21285\n","312/312 [==============================] - 1610s 5s/step - loss: 0.0662 - accuracy: 0.9799 - val_loss: 0.2199 - val_accuracy: 0.9365 - lr: 8.0000e-06\n","Epoch 23/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9803\n","Epoch 00023: val_loss did not improve from 0.21285\n","312/312 [==============================] - 1615s 5s/step - loss: 0.0640 - accuracy: 0.9803 - val_loss: 0.2196 - val_accuracy: 0.9374 - lr: 8.0000e-06\n","Epoch 24/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9806\n","Epoch 00024: val_loss did not improve from 0.21285\n","\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","312/312 [==============================] - 1623s 5s/step - loss: 0.0650 - accuracy: 0.9806 - val_loss: 0.2200 - val_accuracy: 0.9338 - lr: 8.0000e-06\n","Epoch 25/25\n","312/312 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9784\n","Epoch 00025: val_loss did not improve from 0.21285\n","312/312 [==============================] - 1620s 5s/step - loss: 0.0642 - accuracy: 0.9784 - val_loss: 0.2194 - val_accuracy: 0.9347 - lr: 1.6000e-06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TUdQ0v2nkr_","executionInfo":{"status":"ok","timestamp":1607074575989,"user_tz":-360,"elapsed":8212284,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"f4f9fb1d-304b-408e-c608-bd7e7a543f46"},"source":["H = model.fit(data_dict['X'],\n","\tdata_dict['Y'],\n","\tvalidation_data=(data_dict_test['X'],\n","\tdata_dict_test['Y']),\n","\tepochs=5,\n","  callbacks=callbacks,\n","\tverbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","312/312 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9795\n","Epoch 00001: val_loss improved from inf to 0.22073, saving model to final_weights/final64_only_cnn_epoch30.h5\n","312/312 [==============================] - 1637s 5s/step - loss: 0.0632 - accuracy: 0.9795 - val_loss: 0.2207 - val_accuracy: 0.9356 - lr: 1.0000e-06\n","Epoch 2/5\n","312/312 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9778\n","Epoch 00002: val_loss improved from 0.22073 to 0.21737, saving model to final_weights/final64_only_cnn_epoch30.h5\n","312/312 [==============================] - 1636s 5s/step - loss: 0.0658 - accuracy: 0.9778 - val_loss: 0.2174 - val_accuracy: 0.9347 - lr: 1.0000e-06\n","Epoch 3/5\n","312/312 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9804\n","Epoch 00003: val_loss did not improve from 0.21737\n","312/312 [==============================] - 1632s 5s/step - loss: 0.0661 - accuracy: 0.9804 - val_loss: 0.2177 - val_accuracy: 0.9338 - lr: 1.0000e-06\n","Epoch 4/5\n","312/312 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9786\n","Epoch 00004: val_loss did not improve from 0.21737\n","312/312 [==============================] - 1639s 5s/step - loss: 0.0637 - accuracy: 0.9786 - val_loss: 0.2195 - val_accuracy: 0.9356 - lr: 1.0000e-06\n","Epoch 5/5\n","312/312 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9816\n","Epoch 00005: val_loss did not improve from 0.21737\n","312/312 [==============================] - 1640s 5s/step - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.2186 - val_accuracy: 0.9338 - lr: 1.0000e-06\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"37ab6Pk7D1eZ"},"source":["model = model.save(\"final_weights/final64_only_cnn_epoch30th.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGxxEqjeyTtS"},"source":["model = load_model(\"final_weights/final64_only_cnn_epoch20.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyxdASmRJz-c","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"error","timestamp":1606800210793,"user_tz":-360,"elapsed":2011,"user":{"displayName":"Khondokar Prottoy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYmx0b5T6Oon9SAQJf3BECLBq2UA4t7a5eR0lDVQ=s64","userId":"00117656620147166686"}},"outputId":"1740c1f1-4871-48db-8275-c8ac37ec2cd2"},"source":["model.save(\"trained_weights/vgg16_new_elu_epoch25.h5\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a3226575a591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trained_weights/vgg16_new_elu_epoch25.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"7hPyt-rnA7IJ"},"source":["data_dict_evaluate = dict()\n","data_dict_evaluate['X'] = np.load('imglist_test.npy', allow_pickle=True)\n","data_dict_evaluate['X2'] = np.load('poselist_test.npy', allow_pickle=True)\n","data_dict_evaluate['Y'] = np.load('labellist_test.npy', allow_pickle=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCii9R6nBNcy"},"source":["model = load_model(\"final_weights/final64_only_cnn_epoch20.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ji8heIQHA7NY"},"source":["score = model.evaluate({\"ip_img\": data_dict_evaluate['X'], \"ip_pose\": data_dict_evaluate['X2']},\n","\tdata_dict_evaluate['Y'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab_tqUyCyy1x","executionInfo":{"status":"ok","timestamp":1607051251373,"user_tz":-360,"elapsed":61713,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"0376943a-c882-48df-c881-1346d3f2088f"},"source":["score = model.evaluate(data_dict_evaluate['X'],\n","\tdata_dict_evaluate['Y'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 59s 1s/step - loss: 1.1880 - accuracy: 0.6395\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jVWEIaByA7Sf"},"source":["model = load_model('final_weights/final64_only_cnn_epoch30th.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnoCJGJ-A7VC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609931890165,"user_tz":-360,"elapsed":61072,"user":{"displayName":"Khondokar S. S. Prottoy ,160021165","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiyezSatv38KufcX87prkjnKWOuzRY4QvMgRNm=s64","userId":"07098048821585006482"}},"outputId":"e34ee134-6baf-4e33-e8b4-7e34b9eb3f26"},"source":["score = model.evaluate(data_dict_evaluate['X'],\n","\tdata_dict_evaluate['Y'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 60s 1s/step - loss: 0.4010 - accuracy: 0.9000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFwdw54HIzGA","executionInfo":{"status":"ok","timestamp":1607075473136,"user_tz":-360,"elapsed":61371,"user":{"displayName":"Thasin Abedin ,160021139","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJQdb4tw5a_OefpLF2z3yEPD_pWAmIwHtBHC8i-A=s64","userId":"12939580268120638019"}},"outputId":"d930ab25-2cb2-401e-8c35-c123e5495bae"},"source":["score = model.evaluate(data_dict_evaluate['X'],\n","\tdata_dict_evaluate['Y'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 58s 1s/step - loss: 0.4010 - accuracy: 0.9000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ljdF3jrlA7Yi"},"source":[""],"execution_count":null,"outputs":[]}]}